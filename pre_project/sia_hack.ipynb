{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview \n",
    "\n",
    "**Dans ce notebook, on crée notre agent IA et on le prompt pour avoir une solution au porblème de Veolia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pour créer une session et voir si ca marche correctement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session(region_name='us-west-2')\n"
     ]
    }
   ],
   "source": [
    "session = boto3.Session()\n",
    "print(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant lister tous les modèles LLM disponibles dans notre région:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ID: amazon.titan-tg1-large\n",
      "Model ID: amazon.titan-embed-g1-text-02\n",
      "Model ID: amazon.titan-text-lite-v1:0:4k\n",
      "Model ID: amazon.titan-text-lite-v1\n",
      "Model ID: amazon.titan-text-express-v1:0:8k\n",
      "Model ID: amazon.titan-text-express-v1\n",
      "Model ID: amazon.nova-pro-v1:0\n",
      "Model ID: amazon.nova-lite-v1:0\n",
      "Model ID: amazon.nova-micro-v1:0\n",
      "Model ID: amazon.titan-embed-text-v1:2:8k\n",
      "Model ID: amazon.titan-embed-text-v1\n",
      "Model ID: amazon.titan-embed-text-v2:0\n",
      "Model ID: amazon.titan-embed-image-v1:0\n",
      "Model ID: amazon.titan-embed-image-v1\n",
      "Model ID: amazon.titan-image-generator-v1:0\n",
      "Model ID: amazon.titan-image-generator-v1\n",
      "Model ID: amazon.titan-image-generator-v2:0\n",
      "Model ID: amazon.rerank-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1:0\n",
      "Model ID: stability.stable-diffusion-xl-v1\n",
      "Model ID: stability.sd3-large-v1:0\n",
      "Model ID: stability.sd3-5-large-v1:0\n",
      "Model ID: stability.stable-image-core-v1:0\n",
      "Model ID: stability.stable-image-core-v1:1\n",
      "Model ID: stability.stable-image-ultra-v1:0\n",
      "Model ID: stability.stable-image-ultra-v1:1\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20241022-v2:0\n",
      "Model ID: anthropic.claude-3-7-sonnet-20250219-v1:0\n",
      "Model ID: anthropic.claude-3-5-haiku-20241022-v1:0\n",
      "Model ID: anthropic.claude-instant-v1:2:100k\n",
      "Model ID: anthropic.claude-instant-v1\n",
      "Model ID: anthropic.claude-v2:0:18k\n",
      "Model ID: anthropic.claude-v2:0:100k\n",
      "Model ID: anthropic.claude-v2:1:18k\n",
      "Model ID: anthropic.claude-v2:1:200k\n",
      "Model ID: anthropic.claude-v2:1\n",
      "Model ID: anthropic.claude-v2\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:48k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0:200k\n",
      "Model ID: anthropic.claude-3-haiku-20240307-v1:0\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:12k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:28k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0:200k\n",
      "Model ID: anthropic.claude-3-opus-20240229-v1:0\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:18k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:51k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0:200k\n",
      "Model ID: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "Model ID: cohere.command-text-v14:7:4k\n",
      "Model ID: cohere.command-text-v14\n",
      "Model ID: cohere.command-r-v1:0\n",
      "Model ID: cohere.command-r-plus-v1:0\n",
      "Model ID: cohere.command-light-text-v14:7:4k\n",
      "Model ID: cohere.command-light-text-v14\n",
      "Model ID: cohere.embed-english-v3:0:512\n",
      "Model ID: cohere.embed-english-v3\n",
      "Model ID: cohere.embed-multilingual-v3:0:512\n",
      "Model ID: cohere.embed-multilingual-v3\n",
      "Model ID: cohere.rerank-v3-5:0\n",
      "Model ID: deepseek.r1-v1:0\n",
      "Model ID: meta.llama3-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-8b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-1-70b-instruct-v1:0\n",
      "Model ID: meta.llama3-1-405b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-2-11b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-2-90b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-2-1b-instruct-v1:0\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0:128k\n",
      "Model ID: meta.llama3-2-3b-instruct-v1:0\n",
      "Model ID: meta.llama3-3-70b-instruct-v1:0\n",
      "Model ID: mistral.mistral-7b-instruct-v0:2\n",
      "Model ID: mistral.mixtral-8x7b-instruct-v0:1\n",
      "Model ID: mistral.mistral-large-2402-v1:0\n",
      "Model ID: mistral.mistral-large-2407-v1:0\n",
      "Model ID: luma.ray-v2:0\n"
     ]
    }
   ],
   "source": [
    "bedrock = boto3.client('bedrock', region_name='us-west-2') \n",
    "models = bedrock.list_foundation_models()\n",
    "\n",
    "for model in models['modelSummaries']:\n",
    "    print(f\"Model ID: {model['modelId']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va à présent établir une connection à Amazon Redshift, notre base de données serverless:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion réussie !\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du client Redshift Data\n",
    "client = boto3.client('redshift-data', region_name='us-west-2')\n",
    "\n",
    "# Paramètres de connexion\n",
    "database = 'dev'\n",
    "workgroup_name = 'redshift-wg-hackathon'\n",
    "\n",
    "# Requête simple pour tester la connexion\n",
    "sql_query = 'SELECT * from clients_database;'\n",
    "\n",
    "try:\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name, \n",
    "        Sql=sql_query\n",
    "    )\n",
    "    print(\"Connexion réussie !\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va test de faire une requête SQL à Amazon Redshift (notre base de données) et afficher le résultat de la requête: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requête envoyée, ID : be93321d-9379-49b2-9f0e-ecb33ac97a60\n",
      "En attente des résultats...\n",
      "En attente des résultats...\n",
      "\n",
      "Résultats de la requête :\n",
      "['9901', '0', '1', '1', '1', '27257', '470', 'Good', '0', 'NULL', 'NULL', 'NULL', 'NULL', '4', '0', 'Unknown', 'High', 'Moved', '2025-03-09', '26', '18000', 'Unemployed', '1', 'Own', 'Single-family home', '1', 'Suburban', 'Public transportation', '2025-12-03', '226', '0']\n",
      "['9902', '0', '0', '1', '0', '75763', '360', 'Poor', '3', 'Theft', '2024-04-06', 'Standard', '0.37', '1', '1', 'Fragile', 'Poor', 'Moved', '2024-12-27', '57', '18000', 'On-site', '1', 'Rent', 'Townhouse', '0', 'Suburban', 'Car', '2024-09-27', '257', '0']\n",
      "['9903', '0', '0', '0', '1', '51306', '842', 'Good', '0', 'NULL', 'NULL', 'NULL', 'NULL', '6', '0', 'Unknown', 'High', 'Health Issue', '2024-03-07', '67', '18000', 'Remote', '1', 'Own', 'Townhouse', '1', 'Urban', 'Public transportation', '2024-10-30', '420', '0']\n",
      "['9904', '1', '1', '0', '1', '55563', '260', 'Average', '0', 'NULL', 'NULL', 'NULL', 'NULL', '18', '0', 'Fragile', 'High', 'Job Change', '2023-08-08', '40', '35000', 'On-site', '0', 'Own', 'Single-family home', '0', 'Urban', 'Car', '2024-10-08', '239', '0']\n",
      "['9905', '1', '0', '0', '0', '48590', '837', 'Good', '4', 'Accident', '2023-05-13', 'Conflicting', '0.09', '18', '0', 'Unknown', 'High', 'Bought a Car', '2023-09-04', '67', '60000', 'On-site', '1', 'Own', 'Apartment', '1', 'Suburban', 'Public transportation', '2023-10-18', '248', '0']\n",
      "['9906', '0', '1', '1', '1', '15398', '269', 'Average', '0', 'NULL', 'NULL', 'NULL', 'NULL', '8', '0', 'Medium', 'Medium', 'Bought a Property', '2024-10-27', '30', '18000', 'Unemployed', '1', 'Rent', 'Apartment', '0', 'Urban', 'Public transportation', '2024-02-23', '243', '0']\n",
      "['9907', '0', '0', '0', '1', '71510', '596', 'Good', '2', 'General', '2024-05-25', 'Fast', '0.38', '15', '0', 'Fragile', 'Medium', 'Health Issue', '2023-12-22', '49', '35000', 'Remote', '1', 'Own', 'Townhouse', '0', 'Rural', 'Biking', '2024-05-25', '290', '0']\n",
      "['9908', '0', '1', '0', '0', '69865', '728', 'Average', '2', 'Damage', '2025-03-26', 'Conflicting', '0.00', '15', '1', 'Fragile', 'Medium', 'Bought a Property', '2023-04-12', '67', '18000', 'Unemployed', '1', 'Own', 'Townhouse', '1', 'Urban', 'Car', '2025-02-23', '332', '0']\n",
      "['9909', '1', '1', '1', '0', '88237', '153', 'Average', '2', 'Accident', '2024-12-27', 'Fast', '0.26', '7', '0', 'Fragile', 'Poor', 'Bought a Car', '2024-03-22', '32', '18000', 'On-site', '1', 'Own', 'Single-family home', '0', 'Suburban', 'Public transportation', '2023-05-21', '369', '0']\n",
      "['9910', '1', '1', '0', '1', '27073', '494', 'Good', '0', 'NULL', 'NULL', 'NULL', 'NULL', '17', '1', 'Fragile', 'High', 'Bought a Property', '2024-07-06', '53', '18000', 'Hybrid', '1', 'Own', 'Single-family home', '1', 'Urban', 'Car', '2024-05-21', '190', '0']\n"
     ]
    }
   ],
   "source": [
    "sql_query = 'SELECT * FROM clients_database LIMIT 10;' # on limite à 10 lignes\n",
    "\n",
    "try:\n",
    "    # Exécuter la requête SQL\n",
    "    response = client.execute_statement(\n",
    "        Database=database,\n",
    "        WorkgroupName=workgroup_name, \n",
    "        Sql=sql_query\n",
    "    )\n",
    "    \n",
    "    # Récupérer l'ID de l'exécution de la requête\n",
    "    statement_id = response['Id']\n",
    "    print(f\"Requête envoyée, ID : {statement_id}\")\n",
    "\n",
    "    # Attendre que la requête soit terminée\n",
    "    while True:\n",
    "        status_response = client.describe_statement(Id=statement_id)\n",
    "        status = status_response['Status']\n",
    "\n",
    "        if status in ['FINISHED', 'FAILED', 'ABORTED']:\n",
    "            break\n",
    "        print(\"En attente des résultats...\")\n",
    "        time.sleep(2)  # Pause avant la prochaine vérification\n",
    "\n",
    "    # Vérifier si la requête s'est bien exécutée\n",
    "    if status == 'FINISHED':\n",
    "        # Récupérer les résultats\n",
    "        result_response = client.get_statement_result(Id=statement_id)\n",
    "        records = result_response.get('Records', [])\n",
    "\n",
    "        # Afficher les résultats\n",
    "        if records:\n",
    "            print(\"\\nRésultats de la requête :\")\n",
    "            for row in records:\n",
    "                print([col.get('stringValue', 'NULL') for col in row])  # Adaptation pour afficher chaque ligne\n",
    "        else:\n",
    "            print(\"Aucun résultat trouvé.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Erreur lors de l'exécution : {status_response.get('Error', 'Erreur inconnue')}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erreur de connexion ou d'exécution : {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On va maintenant passer à la création de notre agent et aux prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- AWS CONFIGURATION ----\n",
    "AWS_REGION = \"us-west-2\"\n",
    "MODEL_ID = \"\"  # Utilisation de Mistral AI\n",
    "\n",
    "# ---- REDSHIFT SERVERLESS CONFIGURATION ----\n",
    "DATABASE = 'dev'  # nom de notre base de données\n",
    "WORKGROUP_NAME = 'redshift-wg-hackathon'  # notre workgroup\n",
    "\n",
    "# ---- INITIALISATION DES CLIENTS ----\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=AWS_REGION)\n",
    "redshift_client = boto3.client(\"redshift-data\", region_name=AWS_REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Envoi de la requête à Redshift: SELECT * FROM clients_database WHERE Last_Account_Update = 1;\n",
      "✅ Requête envoyée, ID: 0d6f8053-6639-4c40-ab12-137495698742\n",
      "⏳ En attente des résultats...\n",
      "✅ Requête terminée, récupération des résultats...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['6253, 0, 1, 1, 1, 81978, 371, Excellent, 0, NULL, NULL, NULL, NULL, 1, 0, Good, Medium, Bought a Car, 2023-10-29, 52, 18000, Unemployed, 1, Own, Townhouse, 1, Urban, Biking, 2024-01-04, 336, 1',\n",
       " '4743, 1, 0, 0, 1, 86413, 427, Poor, 0, NULL, NULL, NULL, NULL, 2, 0, Fragile, Poor, Bought a Property, 2023-07-22, 43, 18000, Hybrid, 1, Own, Single-family home, 1, Urban, Biking, 2024-12-19, 167, 1',\n",
       " '4685, 1, 1, 0, 0, 46627, 758, Good, 0, NULL, NULL, NULL, NULL, 5, 0, Good, Poor, New Baby, 2024-04-04, 24, 35000, Remote, 1, Rent, Townhouse, 0, Urban, Car, 2024-06-06, 253, 1',\n",
       " '4522, 1, 1, 1, 0, 53395, 683, Good, 0, NULL, NULL, NULL, NULL, 18, 0, Medium, Poor, Moved, 2024-10-10, 43, 35000, Remote, 0, Own, Apartment, 0, Urban, Biking, 2023-07-16, 484, 1',\n",
       " '1732, 0, 1, 0, 0, 45841, 832, Average, 0, NULL, NULL, NULL, NULL, 6, 0, Fragile, High, Moved, 2023-11-11, 70, 35000, Unemployed, 1, Own, Apartment, 0, Urban, Walking, 2023-05-30, 249, 1']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- FONCTION POUR RÉCUPÉRER UN ÉCHANTILLON D'UNE TABLE ----\n",
    "def get_table_sample():\n",
    "    \"\"\"Récupère 100 lignes d'une table Redshift pour analyse.\"\"\"\n",
    "    sql_query = f\"SELECT * FROM clients_database WHERE Last_Account_Update = 1;\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"🔄 Envoi de la requête à Redshift: {sql_query}\")\n",
    "        response = redshift_client.execute_statement(\n",
    "            Database=DATABASE,\n",
    "            WorkgroupName=WORKGROUP_NAME,\n",
    "            Sql=sql_query\n",
    "        )\n",
    "\n",
    "        statement_id = response['Id']\n",
    "        print(f\"✅ Requête envoyée, ID: {statement_id}\")\n",
    "\n",
    "        # Timeout après 60 secondes\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            status_response = redshift_client.describe_statement(Id=statement_id)\n",
    "            status = status_response[\"Status\"]\n",
    "\n",
    "            if status in [\"FINISHED\", \"FAILED\", \"ABORTED\"]:\n",
    "                break\n",
    "            \n",
    "            # Vérification du timeout (60 secondes max)\n",
    "            if time.time() - start_time > 60:\n",
    "                print(\"⏳ Timeout dépassé (60s). Annulation de la requête.\")\n",
    "                return \"Timeout: La requête a pris trop de temps.\"\n",
    "\n",
    "            print(\"⏳ En attente des résultats...\")\n",
    "            time.sleep(3)  # Vérification toutes les 3 secondes\n",
    "\n",
    "        if status == \"FINISHED\":\n",
    "            print(\"✅ Requête terminée, récupération des résultats...\")\n",
    "            result_response = redshift_client.get_statement_result(Id=statement_id)\n",
    "            records = [\n",
    "                \", \".join([col.get('stringValue', 'NULL') for col in row])\n",
    "                for row in result_response.get(\"Records\", [])\n",
    "            ]\n",
    "            return records if records else \"Aucune donnée trouvée.\"\n",
    "        else:\n",
    "            print(f\"❌ Erreur d'exécution: {status}\")\n",
    "            return f\"Erreur lors de l'exécution: {status_response.get('Error', 'Erreur inconnue')}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur de connexion ou d'exécution : {str(e)}\")\n",
    "        return f\"Erreur : {str(e)}\"\n",
    "    \n",
    "\n",
    "get_table_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\zinii\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: utils in c:\\users\\zinii\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def load_pdf_text(path):\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\\n\".join(page.extract_text() for page in reader.pages if page.extract_text())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(client_rows, column_doc, contracts_doc):\n",
    "    header = (\n",
    "        \"You are an AI agent working for an insurance company.\\n\"\n",
    "        \"You have access to:\\n\"\n",
    "        \"- the client data from the 'clients_database' table\\n\"\n",
    "        \"- a document explaining each column ('Explanations about each columns of the clients dataset')\\n\"\n",
    "        \"- a document describing the available insurance contracts and their eligibility criteria ('The different types of insurance contracts and details')\\n\\n\"\n",
    "        \"For each client below, identify the most suitable insurance contract based on their data and the criteria described. \"\n",
    "        \"Return the results in the following format:\\n\\n\"\n",
    "        \"- Client_ID: <ID>\\n\"\n",
    "        \"- Reasons: <Value> (<ColumnName>), ...\\n\"\n",
    "        \"- Suggested Contract: <Contract Name>\\n\\n\"\n",
    "    )\n",
    "\n",
    "    client_data_section = \"\\n=== Client Data ===\\n\"\n",
    "    for row in client_rows:\n",
    "        client_data_section += f\"{row}\\n\"\n",
    "\n",
    "    docs_section = \"\\n=== Column Documentation ===\\n\" + column_doc\n",
    "    contracts_section = \"\\n=== Contract Descriptions ===\\n\" + contracts_doc\n",
    "\n",
    "    return header + client_data_section + docs_section + contracts_section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Envoi de la requête à Redshift: SELECT * FROM clients_database WHERE Last_Account_Update = 1;\n",
      "✅ Requête envoyée, ID: 92233ad7-0c8c-4e0b-ad23-b1919ec61a02\n",
      "⏳ En attente des résultats...\n",
      "✅ Requête terminée, récupération des résultats...\n",
      "['6253, 0, 1, 1, 1, 81978, 371, Excellent, 0, NULL, NULL, NULL, NULL, 1, 0, Good, Medium, Bought a Car, 2023-10-29, 52, 18000, Unemployed, 1, Own, Townhouse, 1, Urban, Biking, 2024-01-04, 336, 1', '4743, 1, 0, 0, 1, 86413, 427, Poor, 0, NULL, NULL, NULL, NULL, 2, 0, Fragile, Poor, Bought a Property, 2023-07-22, 43, 18000, Hybrid, 1, Own, Single-family home, 1, Urban, Biking, 2024-12-19, 167, 1', '4685, 1, 1, 0, 0, 46627, 758, Good, 0, NULL, NULL, NULL, NULL, 5, 0, Good, Poor, New Baby, 2024-04-04, 24, 35000, Remote, 1, Rent, Townhouse, 0, Urban, Car, 2024-06-06, 253, 1', '4522, 1, 1, 1, 0, 53395, 683, Good, 0, NULL, NULL, NULL, NULL, 18, 0, Medium, Poor, Moved, 2024-10-10, 43, 35000, Remote, 0, Own, Apartment, 0, Urban, Biking, 2023-07-16, 484, 1', '1732, 0, 1, 0, 0, 45841, 832, Average, 0, NULL, NULL, NULL, NULL, 6, 0, Fragile, High, Moved, 2023-11-11, 70, 35000, Unemployed, 1, Own, Apartment, 0, Urban, Walking, 2023-05-30, 249, 1']\n",
      "📤 Envoi à Claude 3.5 Haiku via Bedrock...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'll analyze each client and recommend the most suitable insurance contract based on their data:\\n\\n1. Client ID: 6253\\n- Reasons: Bought a Car (Recent Life Event), Urban Location, Has Car (1)\\n- Suggested Contract: Comprehensive Auto Coverage\\nRationale: Recent car purchase, urban environment, and car ownership suggest need for robust auto insurance with comprehensive protection.\\n\\n2. Client ID: 4743\\n- Reasons: Bought a Property (Recent Life Event), Poor Creditworthiness, Fragile Health, Urban Location\\n- Suggested Contract: Renter's Insurance\\nRationale: Recently bought a property, fragile health indicates need for protection, and current living status suggests renter's insurance is most appropriate.\\n\\n3. Client ID: 4685\\n- Reasons: New Baby (Recent Life Event), Remote Work, Medium Income, Urban Location\\n- Suggested Contract: Family Health Plan\\nRationale: New baby, need for comprehensive health coverage, family-oriented life stage suggests family health insurance.\\n\\n4. Client ID: 4522\\n- Reasons: Moved (Recent Life Event), Remote Work, Own Apartment, Urban Location\\n- Suggested Contract: Homeowner's Standard Insurance\\nRationale: Recently moved, owns an apartment, needs standard property protection in urban setting.\\n\\n5. Client ID: 1732\\n- Reasons: Moved (Recent Life Event), Fragile Health, Unemployed, High Risk Profile\\n- Suggested Contract: Basic Health Plan\\nRationale: Fragile health, unemployed status, and need for essential medical coverage point to a basic health insurance plan.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_clients_with_claude():\n",
    "    client_rows = get_table_sample()\n",
    "    print(client_rows)\n",
    "    if not isinstance(client_rows, list):\n",
    "        print(\"❌ Erreur dans la récupération des clients.\")\n",
    "        return\n",
    "\n",
    "    columns_text = load_pdf_text(\"Explanations_about_each_columns_of_the_clients_dataset.pdf\")\n",
    "    contracts_text = load_pdf_text(\"The_different_types_of_insurance_contracts_and_details.pdf\")\n",
    "\n",
    "    prompt = create_prompt(client_rows, columns_text, contracts_text)\n",
    "\n",
    "    request_body = {\n",
    "        \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "        \"max_tokens\": 3000,\n",
    "        \"temperature\": 0.3,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"📤 Envoi à Claude 3.5 Haiku via Bedrock...\")\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=\"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        result = json.loads(response['body'].read())\n",
    "        return result['content'][0]['text']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur avec Claude : {e}\")\n",
    "        return f\"Erreur : {str(e)}\"\n",
    "    \n",
    "\n",
    "analyze_clients_with_claude()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Envoi de la requête à Redshift: SELECT * FROM clients_database WHERE Last_Account_Update = 1;\n",
      "✅ Requête envoyée, ID: 5c294dad-cafb-4c83-974e-6fc980c6918b\n",
      "⏳ En attente des résultats...\n",
      "✅ Requête terminée, récupération des résultats...\n",
      "['6253, 0, 1, 1, 1, 81978, 371, Excellent, 0, NULL, NULL, NULL, NULL, 1, 0, Good, Medium, Bought a Car, 2023-10-29, 52, 18000, Unemployed, 1, Own, Townhouse, 1, Urban, Biking, 2024-01-04, 336, 1', '4743, 1, 0, 0, 1, 86413, 427, Poor, 0, NULL, NULL, NULL, NULL, 2, 0, Fragile, Poor, Bought a Property, 2023-07-22, 43, 18000, Hybrid, 1, Own, Single-family home, 1, Urban, Biking, 2024-12-19, 167, 1', '4685, 1, 1, 0, 0, 46627, 758, Good, 0, NULL, NULL, NULL, NULL, 5, 0, Good, Poor, New Baby, 2024-04-04, 24, 35000, Remote, 1, Rent, Townhouse, 0, Urban, Car, 2024-06-06, 253, 1', '4522, 1, 1, 1, 0, 53395, 683, Good, 0, NULL, NULL, NULL, NULL, 18, 0, Medium, Poor, Moved, 2024-10-10, 43, 35000, Remote, 0, Own, Apartment, 0, Urban, Biking, 2023-07-16, 484, 1', '1732, 0, 1, 0, 0, 45841, 832, Average, 0, NULL, NULL, NULL, NULL, 6, 0, Fragile, High, Moved, 2023-11-11, 70, 35000, Unemployed, 1, Own, Apartment, 0, Urban, Walking, 2023-05-30, 249, 1']\n",
      "📤 Envoi à Claude 3.5 Haiku via Bedrock...\n",
      "I'll analyze each client's data and recommend the most suitable insurance contract based on their profile:\n",
      "\n",
      "1. Client ID: 6253\n",
      "- Reasons: Excellent Creditworthiness (Creditworthiness), Bought a Car (Recent_Life_Event), Urban Location (Location)\n",
      "- Suggested Contract: Comprehensive Auto Coverage\n",
      "Rationale: The client recently bought a car, lives in an urban area, and has excellent creditworthiness, making them a good candidate for comprehensive auto insurance.\n",
      "\n",
      "2. Client ID: 4743\n",
      "- Reasons: Poor Creditworthiness (Creditworthiness), Fragile Health (Health_History), Bought a Property (Recent_Life_Event)\n",
      "- Suggested Contract: Comprehensive Home Insurance\n",
      "Rationale: The client recently bought a property, has fragile health (which might indicate a need for financial protection), and has poor creditworthiness, suggesting they would benefit from comprehensive home insurance.\n",
      "\n",
      "3. Client ID: 4685\n",
      "- Reasons: New Baby (Recent_Life_Event), Remote Work (Employment_Status), Good Health (Health_History)\n",
      "- Suggested Contract: Family Health Plan\n",
      "Rationale: The client has a new baby, works remotely, and has good health, making a family health plan an appropriate choice to cover potential family medical needs.\n",
      "\n",
      "4. Client ID: 4522\n",
      "- Reasons: Moved Recently (Recent_Life_Event), Remote Work (Employment_Status), Medium Risk Profile (Risk_Profile)\n",
      "- Suggested Contract: Homeowner's Standard Insurance\n",
      "Rationale: The client recently moved, owns their apartment, and has a medium risk tolerance, suggesting a standard home insurance would provide appropriate coverage.\n",
      "\n",
      "5. Client ID: 1732\n",
      "- Reasons: Fragile Health (Health_History), Unemployed (Employment_Status), High Risk Profile (Risk_Profile)\n",
      "- Suggested Contract: Premium Health Plan\n",
      "Rationale: The client has fragile health, is unemployed, and has a high-risk profile, indicating they would benefit most from a comprehensive premium health plan with extensive coverage.\n"
     ]
    }
   ],
   "source": [
    "result = analyze_clients_with_claude()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Envoi de la requête à Redshift: SELECT * FROM clients_database WHERE Last_Account_Update = 1;\n",
      "✅ Requête envoyée, ID: 47b73e62-a645-4b5f-999a-5598828d6494\n",
      "⏳ En attente des résultats...\n",
      "✅ Requête terminée, récupération des résultats...\n",
      "🔄 Envoi du prompt à Mistral AI...\n",
      "❌ Erreur d'interaction avec Mistral AI : Parameter validation failed:\n",
      "Invalid length for parameter modelId, value: 0, valid min length: 1\n",
      "\n",
      " Rapport d'Anomalies \n",
      "\n",
      "Erreur : Parameter validation failed:\n",
      "Invalid length for parameter modelId, value: 0, valid min length: 1\n"
     ]
    }
   ],
   "source": [
    "# ---- FONCTION POUR DÉTECTER LES ANOMALIES ----\n",
    "def agent_detect_anomalies():\n",
    "    \"\"\"Détecte les anomalies d'une table spécifique dans Redshift via Mistral AI.\"\"\"\n",
    "    table_sample = get_table_sample()\n",
    "    \n",
    "    if isinstance(table_sample, str):\n",
    "        return table_sample  # Si erreur, on la renvoie directement\n",
    "\n",
    "    formatted_sample = \"\\n\".join(table_sample)\n",
    "\n",
    "    # Construction du prompt\n",
    "    prompt = f\"\"\"\n",
    "    Tu es un expert en qualité des données.\n",
    "    {rep_prompt1}\n",
    "    \n",
    "    Voici un échantillon de la table \"{table_name}\":\n",
    "    {formatted_sample}\n",
    "    \n",
    "    Identifie les anomalies (valeurs nulles, doublons, erreurs de format, etc.).\n",
    "    Génère une requête SQL pour afficher les lignes contenant des données incorrectes.\n",
    "\n",
    "    Réponds en suivant ce format :\n",
    "    - **Type d'anomalie** : [Catégorie de l'anomalie]\n",
    "    - **Description** : [Brève explication]\n",
    "    - **Requête SQL** : [Requête pour afficher les données erronées]\n",
    "    \"\"\"\n",
    "\n",
    "    return analyze_with_mistral(prompt)\n",
    "\n",
    "\n",
    "# ---- FONCTION POUR INTERAGIR AVEC MISTRAL AI ----\n",
    "def analyze_with_mistral(prompt):\n",
    "    \"\"\"Envoie un prompt à Mistral AI via Amazon Bedrock.\"\"\"\n",
    "    request_body = {\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 3000,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_p\": 0.9\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        print(\"🔄 Envoi du prompt à Mistral AI...\")\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId=MODEL_ID,\n",
    "            body=json.dumps(request_body)\n",
    "        )\n",
    "        print(\"✅ Réponse reçue de Mistral.\")\n",
    "\n",
    "        response_body = json.loads(response[\"body\"].read())\n",
    "        return response_body.get(\"outputs\", [{}])[0].get(\"text\", \"\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur d'interaction avec Mistral AI : {str(e)}\")\n",
    "        return f\"Erreur : {str(e)}\"\n",
    "\n",
    "\n",
    "# ---- EXÉCUTION ----\n",
    "if __name__ == \"__main__\":\n",
    "    table_name = input(\"🔍 Entrez le nom de la table à analyser : \")\n",
    "    response = agent_detect_anomalies()\n",
    "\n",
    "    print(\"\\n Rapport d'Anomalies \\n\")\n",
    "    print(response)\n",
    "    rep_prompt2 = response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
